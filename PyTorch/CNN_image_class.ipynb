{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2257f006",
   "metadata": {},
   "source": [
    "# Prequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537869f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import shutil\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c7ac8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f429b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"train\"\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                          std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Normalizing values between 0 and 1 makes the model a bit easier to learn the features since they are standardized or capped within a smaller range\n",
    "#Also prevents the values from getting too large during training phase - exploding gradient problem\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_data_path, transform=transformations)\n",
    "\n",
    "val_data_path = \"val\"\n",
    "val_data = torchvision.datasets.ImageFolder(val_data_path, transform=transformations)\n",
    "\n",
    "test_data_path = \"test\"\n",
    "test_data = torchvision.datasets.ImageFolder(test_data_path, transform=transformations)\n",
    "\n",
    "#Training set - for training pass to update the model \n",
    "#Val set - Evaluate how model is generalizing to problem domain rather than fitting to training data not used directly\n",
    "#Test set - To get final evaluation of model  \n",
    "\n",
    "# Dataloader\n",
    "\n",
    "batch_size = 64 #Num of images sent to the network once before updating it\n",
    "\n",
    "train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "num_classes = 151"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa66d1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ae6dd",
   "metadata": {},
   "source": [
    "* Conv layers - Extract features from images. From general/high level to lower level/intricate specialized features \n",
    "* ReLU - Adds non linearlity to let network learn complex features \n",
    "* Pooling - Shrinks spatial size (downsampling), reducing computation and makes features more invariant\n",
    "* Dropout - Randomly dropping weights to increase generalization of the model \n",
    "* FC - Combines/Flattens feature maps to help make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39c7d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): #CNN is the child class inheriting all functionalities from torch.nn.Module\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # Conv -> Relu -> Pool \n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b5dfd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = ''\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db8f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_func, train_data_loader, val_data_loader, epochs, device):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        training_loss = 0.0\n",
    "        training_iterator = 0\n",
    "        valid_loss = 0.0 \n",
    "        model.train() \n",
    "        for batch in train_data_loader:\n",
    "            optimizer.zero_grad()  #Refresh the optimizer for the next batch everytime \n",
    "            inputs, targets = batch \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_func(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()\n",
    "            training_iterator += 1\n",
    "        training_loss /= training_iterator\n",
    "        model.eval()\n",
    "        valid_iterator = 0\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_data_loader:\n",
    "            inputs, targets = batch \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_func(output, targets)\n",
    "            valid_loss += loss\n",
    "            valid_iterator += 1 \n",
    "            preds = torch.max(output, dim=1)[1] # --> Could be a more idomatic approach\n",
    "            correct = torch.eq(preds, targets)\n",
    "            num_correct += torch.sum(correct).item() #Summing how many predictions were true\n",
    "            num_examples += correct.shape[0] #EQuating number of samples in each batch\n",
    "        valid_loss /= valid_iterator\n",
    "        accuracy = num_correct / num_examples\n",
    "        print(f\"Epoch [{epoch}] : Training Loss = {training_loss:.2f}  Validation Loss = {valid_loss:.2f}\")\n",
    "        print(f\"Validation Accuracy -> {accuracy:2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e80cb863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1775d0ef0c04189883ff439982215a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] : Training Loss = 5.10  Validation Loss = 5.02\n",
      "Epoch [1] : Training Loss = 5.02  Validation Loss = 5.02\n",
      "Epoch [2] : Training Loss = 5.02  Validation Loss = 5.02\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_data_loader, val_data_loader, 3, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78681b19",
   "metadata": {},
   "source": [
    "One thing I noticed was the book talking about using the torchvision ImageFolder functionality to load the dataset, could be a bit complicated since I have folders now instead of a single one, but maybe next time would like to check with the \"Datasets\" class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbd561",
   "metadata": {},
   "source": [
    "Also *Differential Learning Rate* was an important concept I got to read about. \n",
    "\n",
    "Need to check if its still happening or used.\n",
    "\n",
    "So in FT we don't need to impact the weights of the layers that were previoulsy trained, except maybe BatchNorm since we want the normalization to our dataset. So what about a general learning rate for the layers we want to finetune properly (the last and/or the classification ones) and a very very low learning rate for the layers we do not want to affect directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf54bc2",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16084443",
   "metadata": {},
   "source": [
    "https://cs231n.github.io/transfer-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69dd75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Snowwolf\\miniconda3\\envs\\pyt-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Snowwolf\\miniconda3\\envs\\pyt-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Loading the pretrained model\n",
    "model = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ba633a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the pretrained model as a feature extractor part only\n",
    "\n",
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False #Freezing every layer \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e92fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(in_features, num_classes)\n",
    "model.classifier[6].requires_grad_ = True\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.classifier[6].parameters(), lr=0.001) #Only passing the parameters of the classification layers / Can also try with the last modified layer only\n",
    "\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) #Decay lr by a factor of 0.1 every 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77c00e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_func, train_data_loader, val_data_loader, epochs, device):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        training_loss = 0.0\n",
    "        training_iterator = 0\n",
    "        valid_loss = 0.0 \n",
    "        model.train() \n",
    "        for batch in train_data_loader:\n",
    "            optimizer.zero_grad()  #Refresh the optimizer for the next batch everytime \n",
    "            inputs, targets = batch \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_func(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()\n",
    "            training_iterator += 1\n",
    "        training_loss /= training_iterator\n",
    "        model.eval()\n",
    "        valid_iterator = 0\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_data_loader:\n",
    "            inputs, targets = batch \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_func(output, targets)\n",
    "            valid_loss += loss\n",
    "            valid_iterator += 1 \n",
    "            preds = torch.max(output, dim=1)[1] # --> Could be a more idomatic approach\n",
    "            correct = torch.eq(preds, targets)\n",
    "            num_correct += torch.sum(correct).item() #Summing how many predictions were true\n",
    "            num_examples += correct.shape[0] #EQuating number of samples in each batch\n",
    "        valid_loss /= valid_iterator\n",
    "        accuracy = num_correct / num_examples\n",
    "        print(f\"Epoch [{epoch}] : Training Loss = {training_loss:.2f}  Validation Loss = {valid_loss:.2f}\")\n",
    "        print(f\"Validation Accuracy -> {accuracy:2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39fb4523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2d35b5f1b140f98c69fe663de6f190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] : Training Loss = 5.72  Validation Loss = 4.87\n",
      "Validation Accuracy -> 0.027226\n",
      "Epoch [1] : Training Loss = 5.36  Validation Loss = 4.61\n",
      "Validation Accuracy -> 0.060338\n",
      "Epoch [2] : Training Loss = 5.07  Validation Loss = 4.39\n",
      "Validation Accuracy -> 0.100074\n",
      "Epoch [3] : Training Loss = 4.81  Validation Loss = 4.22\n",
      "Validation Accuracy -> 0.132450\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_data_loader, val_data_loader, 4, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cece34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Snowwolf\\miniconda3\\envs\\pyt-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Snowwolf\\miniconda3\\envs\\pyt-dl\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Create only the last fc layer\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "in_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(in_features, num_classes)\n",
    "model.classifier[6].requires_grad_ = True\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.classifier[6].parameters(), lr=0.001) #Only passing the parameters of the classification layers / Can also try with the last modified layer only\n",
    "\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) #Decay lr by a factor of 0.1 every 7 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419aa8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158945d366ed4f10b070f1dab961b162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_data_loader, val_data_loader, 4, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e854ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finetune only clasifer layers\n",
    "model = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False #Freezing all layers first\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        param.requires_grad = True #Keeping only the classification layers trainable\n",
    "\n",
    "in_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(in_features, num_classes)\n",
    "model.classifier[6].requires_grad_ = True \n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.classifier.parameters(), lr=0.001) #Not to forget to set the parameters for the layers we are finetuning, cause when i ignored that my accuracy went down heavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51144d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5891f31a0c3b48a4b7c394c2c234a02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] : Training Loss = 5.60  Validation Loss = 4.80\n",
      "Validation Accuracy -> 0.045622\n",
      "Epoch [1] : Training Loss = 5.12  Validation Loss = 4.60\n",
      "Validation Accuracy -> 0.089772\n",
      "Epoch [2] : Training Loss = 4.84  Validation Loss = 4.43\n",
      "Validation Accuracy -> 0.126564\n",
      "Epoch [3] : Training Loss = 4.61  Validation Loss = 4.28\n",
      "Validation Accuracy -> 0.141280\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, train_data_loader, val_data_loader, 4, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

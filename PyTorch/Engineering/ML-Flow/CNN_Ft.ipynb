{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d126c613",
   "metadata": {},
   "source": [
    "# Prequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets \n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from mlflow.models import infer_signature\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05b85e",
   "metadata": {},
   "source": [
    "https://mlflow.org/docs/latest/ml/deep-learning/pytorch/guide\n",
    "\n",
    "Command to run in the parent \"mlruns\" folder - **mlflow server --host 127.0.0.1 --port 8080**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22ceea2",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330d80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"..//..//train\"\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                          std = [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_data_path, transform=transformations)\n",
    "\n",
    "val_data_path = \"..//..//val\"\n",
    "val_data = torchvision.datasets.ImageFolder(val_data_path, transform=transformations)\n",
    "\n",
    "test_data_path = \"..//..//test\"\n",
    "test_data = torchvision.datasets.ImageFolder(test_data_path, transform=transformations)\n",
    "\n",
    "# Dataloader\n",
    "\n",
    "batch_size = 256 #Num of images sent to the network once before updating it\n",
    "\n",
    "train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "val_data_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "num_classes = 151"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2981304",
   "metadata": {},
   "source": [
    "# MobileNetV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc94591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torchvision.models.mobilenet_v3_small(weights=torchvision.models.MobileNet_V3_Small_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9a9470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model1.parameters():\n",
    "    layer.requires_grad = False\n",
    "\n",
    "for name, layer in model1.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        layer.requires_grad = True\n",
    "\n",
    "in_features = model1.classifier[3].in_features \n",
    "model1.classifier[3] = torch.nn.Linear(in_features, num_classes)\n",
    "model1.classifier[3].requires_grad_ = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model1 = model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b308817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up training parameters \n",
    "\n",
    "params = { \n",
    "    \"epochs\" : 5,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"optimizer\" : \"SGD\",\n",
    "    \"model_type\" : \"Mobile_Net_V3_Small\",\n",
    "    \"pretrained\" : \"True\",\n",
    "    \"frozen_layers\" : \"True\",\n",
    "    \"classifier_out_features\" : num_classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23871101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25086c88e6864f0aad9559488272b9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/5 Train Loss : 5.1271, Train Accuracy : 0.4799% Val Loss : 5.0858, Val Accuracy : 0.5887%\n",
      "Epoch : 2/5 Train Loss : 5.1109, Train Accuracy : 0.5183% Val Loss : 5.0740, Val Accuracy : 0.6623%\n",
      "Epoch : 3/5 Train Loss : 5.0978, Train Accuracy : 0.5087% Val Loss : 5.0626, Val Accuracy : 0.6623%\n",
      "Epoch : 4/5 Train Loss : 5.0849, Train Accuracy : 0.5759% Val Loss : 5.0518, Val Accuracy : 0.6623%\n",
      "Epoch : 5/5 Train Loss : 5.0708, Train Accuracy : 0.6814% Val Loss : 5.0412, Val Accuracy : 0.6623%\n",
      "Final Test Acc : 0.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/27 11:44:12 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/27 11:44:21 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.23.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torchvision==0.23.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Successfully registered model 'mobilenet_v3_small'.\n",
      "Created version '1' of model 'mobilenet_v3_small'.\n"
     ]
    }
   ],
   "source": [
    "#Mlflow Training and logging\n",
    "\n",
    "with mlflow.start_run(run_name=\"mobilenet_v3_small\"):\n",
    "    \n",
    "    # 1 -> Logging the parameters\n",
    "    mlflow.log_params(params) \n",
    "\n",
    "    # 2. -> Model preparation\n",
    "    model = model1\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.classifier.parameters(), lr=params[\"learning_rate\"])\n",
    "\n",
    "    # 3 -> Log Model Architecture\n",
    "    with open(\"mobilenet_v3_small_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model, input_size = (1, 3, 64, 64))))\n",
    "    mlflow.log_artifact(\"mobilenet_v3_small_summary.txt\")\n",
    "\n",
    "    # 4 -> Training loop + Metric Logging\n",
    "    for epoch in tqdm(range(params['epochs'])):\n",
    "        model.train()\n",
    "        train_loss = 0 \n",
    "        correct = 0 \n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            if batch_idx % 100: #logging every 100 batches\n",
    "                batch_loss = train_loss / (batch_idx + 1)\n",
    "                batch_acc = 100 * correct/total # Percentage\n",
    "                mlflow.log_metrics({\"batch_loss\" : batch_loss,\n",
    "                                    \"batch_accuracy\" : batch_acc},\n",
    "                                    step = epoch*len(train_data_loader) + batch_idx,)\n",
    "                \n",
    "            epoch_loss = train_loss / len(train_data_loader)\n",
    "            epoch_acc = 100 * correct/total\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0 \n",
    "            val_correct = 0 \n",
    "            val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_data_loader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_data_loader)\n",
    "        val_acc = 100 * val_correct/val_total \n",
    "        mlflow.log_metrics({\"train_loss\" : epoch_loss,\n",
    "                            \"train_accuracy\" : epoch_acc,\n",
    "                            \"val_loss\" : val_loss,\n",
    "                            \"val_accuracy\" : val_acc},\n",
    "                            step = epoch\n",
    "                            )\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1}/{params['epochs']}\",\n",
    "            f\"Train Loss : {epoch_loss:.4f}, Train Accuracy : {epoch_acc:.4f}%\",\n",
    "            f\"Val Loss : {val_loss:.4f}, Val Accuracy : {val_acc:.4f}%\"\n",
    "            )\n",
    "            \n",
    "            #Logging the trained model \n",
    "            # model_info = mlflow.pytorch.log_model(model, name = \"mobilenet_v3_small\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0 \n",
    "    test_total = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            test_total += target.size(0)\n",
    "            test_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_data_loader)\n",
    "    test_acc = 100 * test_correct / test_total \n",
    "    mlflow.log_metrics({\"test_loss\" : test_loss,\n",
    "                        \"test_accuracy\" : test_acc})\n",
    "    print(f\"Final Test Acc : {test_acc:.2f}%\")\n",
    "\n",
    "    sample_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "    output = model(sample_input)\n",
    "    sample_output = output.cpu().detach().numpy()\n",
    "    signature = infer_signature(sample_input.cpu().numpy(), sample_output)\n",
    "    model_info = mlflow.pytorch.log_model(model,\n",
    "                                          #artifact_path=\"mobilenet_v3_small\", \n",
    "                                          name = \"mobilenet_v3_small\", \n",
    "                                          registered_model_name=\"mobilenet_v3_small\",\n",
    "                                          signature=signature)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33abc23",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d244010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torchvision.models.alexnet(weights=torchvision.models.AlexNet_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c1d122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model2.parameters():\n",
    "    layer.requires_grad = False\n",
    "\n",
    "for name, layer in model2.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        layer.requires_grad = True\n",
    "\n",
    "in_features = model2.classifier[6].in_features \n",
    "model2.classifier[6] = torch.nn.Linear(in_features, num_classes)\n",
    "model2.classifier[6].requires_grad_ = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a899fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up training parameters \n",
    "\n",
    "params = { \n",
    "    \"epochs\" : 5,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"optimizer\" : \"SGD\",\n",
    "    \"model_type\" : \"Alexnet\",\n",
    "    \"pretrained\" : \"True\",\n",
    "    \"frozen_layers\" : \"True\",\n",
    "    \"classifier_out_features\" : num_classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a401511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea9784071c145279bd378fb0c3ebb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/5 Train Loss : 6.5671, Train Accuracy : 0.2687% Val Loss : 5.5510, Val Accuracy : 0.8094%\n",
      "Epoch : 2/5 Train Loss : 5.8702, Train Accuracy : 0.6047% Val Loss : 5.2050, Val Accuracy : 2.6490%\n",
      "Epoch : 3/5 Train Loss : 5.4337, Train Accuracy : 1.5357% Val Loss : 4.9219, Val Accuracy : 3.9735%\n",
      "Epoch : 4/5 Train Loss : 5.1006, Train Accuracy : 2.9273% Val Loss : 4.6835, Val Accuracy : 5.5923%\n",
      "Epoch : 5/5 Train Loss : 4.8298, Train Accuracy : 4.6166% Val Loss : 4.4909, Val Accuracy : 7.5791%\n",
      "Final Test Acc : 8.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/27 12:40:56 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/27 12:41:03 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.23.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torchvision==0.23.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Successfully registered model 'alexnet'.\n",
      "Created version '1' of model 'alexnet'.\n"
     ]
    }
   ],
   "source": [
    "#Mlflow Training and logging\n",
    "\n",
    "with mlflow.start_run(run_name=\"Alexnet\"):\n",
    "    \n",
    "    # 1 -> Logging the parameters\n",
    "    mlflow.log_params(params) \n",
    "\n",
    "    # 2. -> Model preparation\n",
    "    model = model2\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.classifier.parameters(), lr=params[\"learning_rate\"])\n",
    "\n",
    "    # 3 -> Log Model Architecture\n",
    "    with open(\"alexnet_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model, input_size = (1, 3, 64, 64))))\n",
    "    mlflow.log_artifact(\"alexnet_summary.txt\")\n",
    "\n",
    "    # 4 -> Training loop + Metric Logging\n",
    "    for epoch in tqdm(range(params['epochs'])):\n",
    "        model.train()\n",
    "        train_loss = 0 \n",
    "        correct = 0 \n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            if batch_idx % 100: #logging every 100 batches\n",
    "                batch_loss = train_loss / (batch_idx + 1)\n",
    "                batch_acc = 100 * correct/total # Percentage\n",
    "                mlflow.log_metrics({\"batch_loss\" : batch_loss,\n",
    "                                    \"batch_accuracy\" : batch_acc},\n",
    "                                    step = epoch*len(train_data_loader) + batch_idx,)\n",
    "                \n",
    "            epoch_loss = train_loss / len(train_data_loader)\n",
    "            epoch_acc = 100 * correct/total\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0 \n",
    "            val_correct = 0 \n",
    "            val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_data_loader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_data_loader)\n",
    "        val_acc = 100 * val_correct/val_total \n",
    "        mlflow.log_metrics({\"train_loss\" : epoch_loss,\n",
    "                            \"train_accuracy\" : epoch_acc,\n",
    "                            \"val_loss\" : val_loss,\n",
    "                            \"val_accuracy\" : val_acc},\n",
    "                            step = epoch\n",
    "                            )\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1}/{params['epochs']}\",\n",
    "            f\"Train Loss : {epoch_loss:.4f}, Train Accuracy : {epoch_acc:.4f}%\",\n",
    "            f\"Val Loss : {val_loss:.4f}, Val Accuracy : {val_acc:.4f}%\"\n",
    "            )\n",
    "            \n",
    "            #Logging the trained model \n",
    "            # model_info = mlflow.pytorch.log_model(model, name = \"mobilenet_v3_small\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0 \n",
    "    test_total = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            test_total += target.size(0)\n",
    "            test_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_data_loader)\n",
    "    test_acc = 100 * test_correct / test_total \n",
    "    mlflow.log_metrics({\"test_loss\" : test_loss,\n",
    "                        \"test_accuracy\" : test_acc})\n",
    "    print(f\"Final Test Acc : {test_acc:.2f}%\")\n",
    "\n",
    "    sample_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "    output = model(sample_input)\n",
    "    sample_output = output.cpu().detach().numpy()\n",
    "    signature = infer_signature(sample_input.cpu().numpy(), sample_output)\n",
    "    model_info = mlflow.pytorch.log_model(model,\n",
    "                                          #artifact_path=\"mobilenet_v3_small\", \n",
    "                                          name = \"alexnet\", \n",
    "                                          registered_model_name=\"alexnet\",\n",
    "                                          signature=signature)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32ffae",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25142f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1330985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model3.parameters():\n",
    "    layer.requires_grad = False\n",
    "\n",
    "for name, layer in model3.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        layer.requires_grad = True\n",
    "\n",
    "in_features = model3.classifier[6].in_features \n",
    "model3.classifier[6] = torch.nn.Linear(in_features, num_classes)\n",
    "model3.classifier[6].requires_grad_ = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model3 = model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d460ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up training parameters \n",
    "\n",
    "params = { \n",
    "    \"epochs\" : 5,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"optimizer\" : \"SGD\",\n",
    "    \"model_type\" : \"Alexnet\",\n",
    "    \"pretrained\" : \"True\",\n",
    "    \"frozen_layers\" : \"True\",\n",
    "    \"classifier_out_features\" : num_classes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2c34339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cf2e785e8c4176adea7a7b08623449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/5 Train Loss : 13.8407, Train Accuracy : 0.0096% Val Loss : 10.1314, Val Accuracy : 0.1472%\n",
      "Epoch : 2/5 Train Loss : 9.1582, Train Accuracy : 0.0384% Val Loss : 8.4169, Val Accuracy : 0.2943%\n",
      "Epoch : 3/5 Train Loss : 8.0168, Train Accuracy : 0.0768% Val Loss : 7.7191, Val Accuracy : 0.2208%\n",
      "Epoch : 4/5 Train Loss : 7.4512, Train Accuracy : 0.1728% Val Loss : 7.2807, Val Accuracy : 0.2943%\n",
      "Epoch : 5/5 Train Loss : 7.0681, Train Accuracy : 0.2975% Val Loss : 6.9390, Val Accuracy : 0.5887%\n",
      "Final Test Acc : 0.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/27 12:52:38 WARNING mlflow.utils.requirements_utils: Found torch version (2.8.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.8.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/09/27 12:52:47 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.23.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torchvision==0.23.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Successfully registered model 'vgg16'.\n",
      "Created version '1' of model 'vgg16'.\n"
     ]
    }
   ],
   "source": [
    "#Mlflow Training and logging\n",
    "\n",
    "with mlflow.start_run(run_name=\"VGG16\"):\n",
    "    \n",
    "    # 1 -> Logging the parameters\n",
    "    mlflow.log_params(params) \n",
    "\n",
    "    # 2. -> Model preparation\n",
    "    model = model2\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.classifier.parameters(), lr=params[\"learning_rate\"])\n",
    "\n",
    "    # 3 -> Log Model Architecture\n",
    "    with open(\"vgg16_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model, input_size = (1, 3, 64, 64))))\n",
    "    mlflow.log_artifact(\"vgg16_summary.txt\")\n",
    "\n",
    "    # 4 -> Training loop + Metric Logging\n",
    "    for epoch in tqdm(range(params['epochs'])):\n",
    "        model.train()\n",
    "        train_loss = 0 \n",
    "        correct = 0 \n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            if batch_idx % 100: #logging every 100 batches\n",
    "                batch_loss = train_loss / (batch_idx + 1)\n",
    "                batch_acc = 100 * correct/total # Percentage\n",
    "                mlflow.log_metrics({\"batch_loss\" : batch_loss,\n",
    "                                    \"batch_accuracy\" : batch_acc},\n",
    "                                    step = epoch*len(train_data_loader) + batch_idx,)\n",
    "                \n",
    "            epoch_loss = train_loss / len(train_data_loader)\n",
    "            epoch_acc = 100 * correct/total\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0 \n",
    "            val_correct = 0 \n",
    "            val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_data_loader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_data_loader)\n",
    "        val_acc = 100 * val_correct/val_total \n",
    "        mlflow.log_metrics({\"train_loss\" : epoch_loss,\n",
    "                            \"train_accuracy\" : epoch_acc,\n",
    "                            \"val_loss\" : val_loss,\n",
    "                            \"val_accuracy\" : val_acc},\n",
    "                            step = epoch\n",
    "                            )\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1}/{params['epochs']}\",\n",
    "            f\"Train Loss : {epoch_loss:.4f}, Train Accuracy : {epoch_acc:.4f}%\",\n",
    "            f\"Val Loss : {val_loss:.4f}, Val Accuracy : {val_acc:.4f}%\"\n",
    "            )\n",
    "            \n",
    "            #Logging the trained model \n",
    "            # model_info = mlflow.pytorch.log_model(model, name = \"mobilenet_v3_small\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0 \n",
    "    test_total = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            test_total += target.size(0)\n",
    "            test_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_data_loader)\n",
    "    test_acc = 100 * test_correct / test_total \n",
    "    mlflow.log_metrics({\"test_loss\" : test_loss,\n",
    "                        \"test_accuracy\" : test_acc})\n",
    "    print(f\"Final Test Acc : {test_acc:.2f}%\")\n",
    "\n",
    "    sample_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "    output = model(sample_input)\n",
    "    sample_output = output.cpu().detach().numpy()\n",
    "    signature = infer_signature(sample_input.cpu().numpy(), sample_output)\n",
    "    model_info = mlflow.pytorch.log_model(model,\n",
    "                                          #artifact_path=\"mobilenet_v3_small\", \n",
    "                                          name = \"vgg16\", \n",
    "                                          registered_model_name=\"vgg16\",\n",
    "                                          signature=signature)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5dd6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

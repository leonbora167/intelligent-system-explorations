{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ca0bfd",
   "metadata": {},
   "source": [
    "# ReRanking + Hybrid BM25 + FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63dd2bc",
   "metadata": {},
   "source": [
    "* BM25 = classical information retrieval scoring function \n",
    "* \"A document is relevant if it contains same words as queries especially rare words\"\n",
    "* BM25 scores documents based on **Tf-IDF**, **IDF**, **Document length normalization**\n",
    "* Issue is does not understand meaning/semantics \n",
    "* BM25 looks for exact word matching, very precise\n",
    "* FAISS through query->embeddings looks for documents which are similar in context/semantic\n",
    "* FAISS -> semantic recall \n",
    "* BM25 + FAISS -> Great approach for real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d755f43",
   "metadata": {},
   "source": [
    "* Retrieval -> Which documents *might* be relevant ?\n",
    "* Reranking -> Which of these retrieved is *actually* the best for this query ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5640cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_classic.schema import Document\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_classic.retrievers import EnsembleRetriever\n",
    "from langchain_classic.retrievers import ContextualCompressionRetriever \n",
    "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker \n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from sentence_transformers import CrossEncoder\n",
    "import json, os\n",
    "from langchain_huggingface import HuggingFacePipeline \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from langchain_classic.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e798446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded documents are  228\n",
      "Example of one document \n",
      "  34 Harry Potter  \n",
      " \n",
      "been trying to do. He shouted at Harry for about half an hour and \n",
      "then told him to go and make a cup of tea. Harry shuffled miser-\n",
      "ably off into the kitchen, and by the time he got back, the post  \n",
      "had arrived, right into Uncle V\n"
     ]
    }
   ],
   "source": [
    "#Load pdf\n",
    "pdf_path = \"book1.pdf\"\n",
    "pdf = PyPDFLoader(pdf_path)\n",
    "docs = pdf.load() \n",
    "print(\"Number of loaded documents are \", len(docs))\n",
    "print(\"Example of one document \\n \", docs[35].page_content[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817e5ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created  1057\n"
     ]
    }
   ],
   "source": [
    "#Create chunks \n",
    "chunk_size = 600 \n",
    "chunk_overlap = 150 \n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
    "                                          chunk_overlap=chunk_overlap,\n",
    "                                          separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "                                          )\n",
    "chunked_docs = splitter.split_documents(docs)\n",
    "print(\"Chunks created \", len(chunked_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376a34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load embeddings model\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name = \"KaLM-Embedding/KaLM-embedding-multilingual-mini-instruct-v2.5\",\n",
    "                                         model_kwargs = {\"device\" : \"cuda\"},\n",
    "                                         encode_kwargs = {\"normalize_embeddings\" : True})\n",
    "\n",
    "#Create vector store from embeddings model \n",
    "vectorstore = FAISS.from_documents(chunked_docs, embedding=embeddings_model)\n",
    "vectorstore.save_local(\"faiss_book1_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11acd9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating retriever for chain operations \n",
    "faiss_retriever = vectorstore.as_retriever(search_type=\"similarity\",\n",
    "                                           search_kwargs = {\"k\":3})\n",
    "\n",
    "#Load BM25 Retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(chunked_docs)\n",
    "bm25_retriever.k =5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a8069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever],\n",
    "                                     weights = [0.4, 0.6] #FAISS Gets more weights -> check why\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf15ceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chasing him as usual when, as much to Harry’s surprise as anyone \n",
      "else’s, there he was sitting on th\n",
      "was screaming! Harry snapped it shut, but the shriek went on and \n",
      "on, one high, unbroken, ear-splitt\n",
      "mouldy blankets in the second room and made up a bed for \n",
      "Dudley on the moth-eaten sofa. She and Unc\n",
      "was dreading the dawn. What would happen when the rest of \n",
      "Gryffindor found out what they’d done? \n",
      "A\n",
      "90 Harry Potter  \n",
      " \n",
      "Sometimes, Harry noticed, the hat shouted out the house at \n",
      "once, but at others \n",
      "156 Harry Potter  \n",
      " \n",
      "‘Why not?’ \n",
      "‘I dunno, I’ve just got a bad feeling about it – and anyway, \n",
      "you’v\n",
      "tank had vanished. The great snak e was uncoiling itself rapidly, \n",
      "slithering out on to the floor – \n",
      "will have classes with the rest of your house, sleep in your house \n",
      "dormitory and spend free time in\n"
     ]
    }
   ],
   "source": [
    "# Hybrid retriever test \n",
    "\n",
    "query = \"What was HArry's house\"\n",
    "docs = hybrid_retriever.invoke(query)\n",
    "\n",
    "for i in docs:\n",
    "    print(i.page_content[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665934b",
   "metadata": {},
   "source": [
    "Only the retrieval has been augmented with embedding + BME25 scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f4621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the reranker\n",
    "reranker_model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\",\n",
    "                                         model_kwargs = {\"device\" : \"cuda\"})\n",
    "reranker =  CrossEncoderReranker(model = reranker_model,\n",
    "                                top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5bce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap hybrid retriever \n",
    "compression_retriever = ContextualCompressionRetriever(base_retriever=hybrid_retriever,\n",
    "                                                       base_compressor=reranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54bc6418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Quidditch season had begun. On Saturday, Harry would be \n",
      "playing in his first match after weeks of training: Gryffindor ver-\n",
      "sus Slytherin. If Gry\n",
      "‘Honestly, Hermione, you think all teachers are saints or some-\n",
      "thing,’ snapped Ron. ‘I’m with Harry. I wouldn’t put anything past \n",
      "Snape. But what’s \n",
      "‘Ron! Ron! Where are you? The game’s over! Harry’s won! \n",
      "We’ve won! Gryffindor are in the lead!’ shrieked Hermione, danc-\n",
      "ing up and down on her seat \n"
     ]
    }
   ],
   "source": [
    "query = \"Did Harry win his Quidditch match ?\"\n",
    "docs = compression_retriever.invoke(query)\n",
    "for i in docs:\n",
    "    print(i.page_content[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c92f6d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "# Loading the llm model to implement on top of this RAG\n",
    "model_name = \"Qwen/Qwen3-0.6B\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"models\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             device_map=\"cuda\",\n",
    "                                             cache_dir=\"models\",\n",
    "                                             dtype=torch.bfloat16)\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer = tokenizer,\n",
    "                max_new_tokens = 32,\n",
    "                temperature = 0.6)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb978a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                       chain_type=\"stuff\", \n",
    "                                       retriever=compression_retriever,\n",
    "                                       return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f50f59f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response : \n",
      " Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "The Quidditch season had begun. On Saturday, Harry would be \n",
      "playing in his first match after weeks of training: Gryffindor ver-\n",
      "sus Slytherin. If Gryffindor won, they would move up into second \n",
      "place in the House Championship. \n",
      "Hardly anyone had seen Harry play because Wood had decided \n",
      "that, as their secret weapon, Harry should be kept, well, secret.  \n",
      "But the news that he was playing Seeker had leaked out somehow, \n",
      "and Harry didn’t know which was worse – people telling him he’d \n",
      "be brilliant or people telling him they’d be running around under-\n",
      "neath him, holding a mattress.\n",
      "\n",
      "‘Honestly, Hermione, you think all teachers are saints or some-\n",
      "thing,’ snapped Ron. ‘I’m with Harry. I wouldn’t put anything past \n",
      "Snape. But what’s he after? What’s that dog guarding?’ \n",
      "Harry went to bed with his head  buzzing with the same ques-\n",
      "tion. Neville was snoring loudly, but Harry couldn’t sleep. He tried \n",
      "to empty his mind – he needed to sleep, he had to, he had his first \n",
      "Quidditch match in a few hours – but the expression on Snape’s \n",
      "face when Harry had seen his leg wasn’t easy to forget. \n",
      "* \n",
      "The next morning dawned very bright and cold. The Great Hall\n",
      "\n",
      "‘Ron! Ron! Where are you? The game’s over! Harry’s won! \n",
      "We’ve won! Gryffindor are in the lead!’ shrieked Hermione, danc-\n",
      "ing up and down on her seat and hugging Parvati Patil in the row \n",
      "in front. \n",
      "Harry jumped off his broom, a foot from the ground. He couldn’t \n",
      "believe it. He’d done it – the game was over; it had barely lasted five \n",
      "minutes. As Gryffindors came spilling on to the pitch, he saw Snape \n",
      "land nearby, white-faced and tight-lipped – then Harry felt a hand \n",
      "on his shoulder and looked up into Dumbledore’s smiling face.\n",
      "\n",
      "Question: Did Harry win his Quidditch match ?\n",
      "Helpful Answer: The Quidditch season had begun. On Saturday, Harry would be playing in his first match after weeks of training: Gryffindor versus Slytherin\n"
     ]
    }
   ],
   "source": [
    "response = qa_chain.invoke({\"query\" : query})\n",
    "print(\"Response : \\n\", response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222568c7",
   "metadata": {},
   "source": [
    "User Query -> BM25 Retriever -> FAISS Retriever -> Score Fusion -> Cross Encoder Reranker -> Top-K Contexxt -> LLM -> Answer + Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958cdbf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

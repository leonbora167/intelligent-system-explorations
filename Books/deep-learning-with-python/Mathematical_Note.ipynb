{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd216c0",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aeb2b7d-e452-45cf-9e8a-b8e4aca170d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f006ff50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images is (60000, 28, 28) \n",
      "Shape of testing Images is (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(f\"Shape of training images is {train_images.shape} \\nShape of testing Images is {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9cd254",
   "metadata": {},
   "source": [
    "There are 60k Images (Rows). Since each Row is represented by 28x28 2D matrix we can say its a Grayscale image of shape 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51b746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa649fa",
   "metadata": {},
   "source": [
    "The labels in MNIST case are the actual value of the image itself represented by an integer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24cd604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models \n",
    "from keras import layers \n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation=\"relu\", input_shape = (28*28,)))\n",
    "network.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "#small note here (28*28) will throw an error since Python recognizes it as an integer (784) while (28*28,) makes it recognize as a tuple of size (784,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a5ba9",
   "metadata": {},
   "source": [
    "* Layers are fundamental building blocks for the data processing. Assuming them as a filter for the data.\n",
    "* Data goes in one form and comes out in another. Hopefully a more meaningful and useful repesentation for the problem at hand.\n",
    "* Simple layers are connected together to form a chain one after the other implementing a form of progressive **distillation**.\n",
    "* Models is like a sieve for data preprocessing made up of successive increasing refined data filters -- layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f618b",
   "metadata": {},
   "source": [
    "* **Loss function** - Measures the performance on the training/eval data to steer itself in the right direction\n",
    "* **Optimizer** - Updates the weights acc to the loss\n",
    "* **Monitoring Metrics** - Calling it Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee5edea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation\n",
    "\n",
    "network.compile(optimizer=\"rmsprop\",\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3515a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images is (60000, 784) \n",
      "Shape of testing Images is (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#Reshape and change data type\n",
    "\n",
    "train_images = train_images.reshape(60000, 28*28)\n",
    "train_images = train_images.astype(\"float32\")/255.0 #Normalize it too\n",
    "\n",
    "test_images = test_images.reshape(10000, 28*28)\n",
    "test_images = test_images.astype(\"float32\")/255.0 \n",
    "\n",
    "print(f\"Shape of training images is {train_images.shape} \\nShape of testing Images is {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a821eb7",
   "metadata": {},
   "source": [
    "Not playing around much in the reshape work, think of it just as unpacking the 28 by 28 pixels image into a flat row of 784 pixels. So u have 60000 rows and each row has 784 columns or call it pixel data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f4c6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "#Encoding labels using keras' in built categorical encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702bbddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 16:30:10.005967: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2025-07-27 16:30:10.133238: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753614010.674773   18175 service.cc:152] XLA service 0x7789a8007470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753614010.674791   18175 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-07-27 16:30:10.695705: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753614010.757553   18175 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 105/7500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.5817 - loss: 1.3292 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753614011.266876   18175 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.3083\n",
      "Epoch 2/3\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9726 - loss: 0.1037\n",
      "Epoch 3/3\n",
      "\u001b[1m7500/7500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - accuracy: 0.9800 - loss: 0.0810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x778a8c8d0c10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images,\n",
    "            train_labels,\n",
    "            epochs=3,\n",
    "            batch_size=8)\n",
    "\n",
    "#Fit is the inbuilt method for training DL models on Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c34cc15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9730 - loss: 0.1361\n",
      "Test accuracy = 0.9763000011444092 \n",
      "Test Loss 0.11742827296257019\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = network.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy = {test_accuracy} \\nTest Loss {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a86ed4",
   "metadata": {},
   "source": [
    "Test accuracy is sloghtly lower than the training accuracy. Its normal sometimes or maybe sometimes can be an issue of other training or data things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde4ec40",
   "metadata": {},
   "source": [
    "# Data Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56422cd",
   "metadata": {},
   "source": [
    "* Tensors are the default representation of data in neural networks. \n",
    "* A container of data\n",
    "* Tensors can refere to arbitrary number dimensions in matrixes. These dimensions can be referred by as axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8c755",
   "metadata": {},
   "source": [
    "## Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a76d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Dimensions are  0\n"
     ]
    }
   ],
   "source": [
    "#Tensor with only number\n",
    "# 0 dimensional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array(12)\n",
    "print(x)\n",
    "print(\"Dimensions are \",x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8be9c8",
   "metadata": {},
   "source": [
    "## Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b2d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "Dimensions are  1\n"
     ]
    }
   ],
   "source": [
    "# Array of numbers\n",
    "# 1 D Tensor\n",
    "# 1 Axis\n",
    "\n",
    "x = np.array([1, 2, 3, 4])\n",
    "print(x)\n",
    "print(\"Dimensions are \", x.ndim)\n",
    "\n",
    "#Here there are 4 values so we ll call it 4D Vector / Not confusing with a 4D Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5362fc",
   "metadata": {},
   "source": [
    "## Matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ace259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Dimensions are  2\n",
      "Shape is  (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Array of vectors\n",
    "# 2D Tensor\n",
    "# 2 Axes\n",
    "# commonly abbreviated as rows and columns\n",
    "x = np.array([[1, 2, 3],\n",
    "             [4, 5, 6],\n",
    "             [7, 8, 9]])\n",
    "\n",
    "print(x)\n",
    "print(\"Dimensions are \", x.ndim)\n",
    "print(\"Shape is \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a86f2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5  2  3]\n",
      "  [ 6  7  8]\n",
      "  [10 11 12]]]\n",
      "Dimensions are  3\n",
      "Shape is  (1, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Array of matrixes \n",
    "# You can keep on packing array within array within arrays\n",
    "# Each time we do this we ll be increasing the dimensions\n",
    "# High dimensional tensors\n",
    "\n",
    "x = np.array([[[5, 2, 3],\n",
    "               [6, 7, 8],\n",
    "               [10, 11, 12]]])\n",
    "\n",
    "print(x)\n",
    "print(\"Dimensions are \",x.ndim)\n",
    "print(\"Shape is \",x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d74a61",
   "metadata": {},
   "source": [
    "* **Axes** = Tensor's n-dim\n",
    "* **Shape** = Tuple of integers describing how many dimensions the tensor has along each axis\n",
    "* **Data Type** = Type of data contained within the container (Tensor); uint8, float16, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba6a7c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "3\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(train_images.ndim)\n",
    "print(train_images.dtype)\n",
    "\n",
    "# For the train images tensor\n",
    "# Dimensions are 3 \n",
    "# Shape for each dimension is respectively 6000, 28 and 28\n",
    "# Data type of tensor is uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b1f3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can manipulate it like arrays - slicing \n",
    "x = train_images[244: 322]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ff03d",
   "metadata": {},
   "source": [
    "| Real world examples\n",
    "* 2D Tensor - Vector Data\n",
    "* 3D Tensor - Timeseries Data\n",
    "* 4D Tensor - Images\n",
    "* 5D Tensor - Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717f6a0",
   "metadata": {},
   "source": [
    "# Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90121d4b",
   "metadata": {},
   "source": [
    "Every layer of a neural network can be represented by a handful of mathematical operations in the end. Each layer takes in a tensor - performs some operation on it - returns another tensor. Ultimately its all about representation and work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c299d",
   "metadata": {},
   "source": [
    "## Element Wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4de47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu\n",
    "# Mathematically Relu is f(a,0)\n",
    "\n",
    "\n",
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 # X Should be a 2D Tensor\n",
    "\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]): #Rows\n",
    "        for j in range(x.shape[1]): #Columns\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49b6d017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0],\n",
       "       [4, 0, 6],\n",
       "       [7, 0, 9]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, -3],\n",
    "             [4, -5, 6],\n",
    "             [7, -8, 9]])\n",
    "\n",
    "naive_relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68f648e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use numpy rather than all these for element wise operations as they are optimized to run blazing fast using \n",
    "# BLAS\n",
    "# Basic Linear Algebra Subprograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79efb9",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a55e1a",
   "metadata": {},
   "source": [
    "On addition of tensors of two different shapes - In presence of no ambiguity - The smaller tensor is broadcasted to match the shape of the larger tensor. \n",
    "\n",
    "Its of two types \n",
    "|\n",
    "* Axes (broadcast axes) are added to smaller tensors to match the ndim of the larger ones\n",
    "* Smaller tensor is repeated alongside the new axes to match the full shape of the larger tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb527669",
   "metadata": {},
   "source": [
    "## Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a142f",
   "metadata": {},
   "source": [
    "* Vector.Vector = Vector\n",
    "* Matrix.Vector = Vector\n",
    "* (a, b, c, d).(d,) -> (a, b, c)\n",
    "* (a, b, c, d).(d, e) -> (a, b, c, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93301f",
   "metadata": {},
   "source": [
    "## Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dd6332",
   "metadata": {},
   "source": [
    "Changing the shape of a tensor to match the target shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f733d171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[0]\n",
      " [2]\n",
      " [1]\n",
      " [4]\n",
      " [7]\n",
      " [8]]\n",
      "[[0 2 1]\n",
      " [4 7 8]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 2],\n",
    "              [1, 4],\n",
    "              [7,8]])\n",
    "print(x.shape)\n",
    "\n",
    "x = x.reshape([6,1])\n",
    "print(x)\n",
    "\n",
    "x = x.reshape([2, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a83d2ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "# Transposing is a special case of reshaping\n",
    "# Exchanging rows and columns\n",
    "# x[i, :] -> x[:, i]\n",
    "\n",
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80bd6a7",
   "metadata": {},
   "source": [
    "# Gradient based optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67856132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
